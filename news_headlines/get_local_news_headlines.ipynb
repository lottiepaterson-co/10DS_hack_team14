{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant packages\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import requests\n",
    "from app.utils import generate\n",
    "\n",
    "\n",
    "county = generate(f\"Which UK county is {placename} in? Respond only with the name of the county.\").rstrip()\n",
    "\n",
    "def local_news_headlines(county):\n",
    "\n",
    "    county_news_matching = pd.read_csv(\"20240416 - Collection-38381111-United Kingdom - State & Local-sources-.csv\")\n",
    "    news_sources = county_news_matching[county_news_matching['county_full']== county]['homepage']\n",
    "    sources_list = ', '.join(news_sources.tolist())\n",
    "    sources_list = sources_list.replace('http://', '')\n",
    "    sources_list = sources_list.replace('/', ' ')\n",
    "\n",
    "\n",
    "    #set the parametres and set up API key for the newscatcher API\n",
    "    url = 'https://v3-api.newscatcherapi.com/api/latest_headlines?'\n",
    "    #themes = ['Business', 'Economics', 'Finance', 'Health', 'Politics', 'Science', 'Tech', 'Crime', 'General']\n",
    "    themes = ['Health, Business, Finance, Economics, Politics, Crime, Science, Tech']\n",
    "    params = { 'q': '*','lang': 'en', 'countries': 'GB', 'when':'24h', 'page_size': 100, 'sort_by': 'relevancy', 'is_headline': True, 'ranked_only': True, 'clustering_enabled': False, 'theme': themes, 'sources':sources_list}\n",
    "    headers = {'x-api-token': '0OV147hPPeTT6S1vpRWiYvN4nDvsa1EN'}\n",
    "    #Call the API to generate clusters of UK news headlines from the past twenty four hours\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "    #Manipulate the results to produce a dataframe showing the title of articles in each cluster, the content of the articles and their sources.\n",
    "    data = response.json()\n",
    "    total_pages = data['total_pages']\n",
    "    current_page = 1\n",
    "    compiled_headlines = []\n",
    "    while current_page < total_pages + 1:\n",
    "        if current_page > 1:\n",
    "            params['page'] = current_page\n",
    "            response = requests.get(url, params=params, headers=headers)\n",
    "            data = response.json()\n",
    "        for article in data['articles']:\n",
    "            compiled_headlines.append([article['title'], article['content'], article['name_source']])\n",
    "        current_page = current_page +1\n",
    "\n",
    "    df = pd.DataFrame(compiled_headlines)\n",
    "    df.columns = ['Title', 'Content', 'Source']\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
